## <u>数据操作</u>

```python
import torch
```

1. **直接创建tensor**

   ```python
   x=torch.tensor([5.5,3])
   ```

   输出

   ```python
   tensor([5.5000, 3.0000])
   ```

   

2. **创建空的tensor**

   ```python
   x=torch.empty(5,3)#(5,3)表示5行3列
   #空的tensor意思是非常接近0的tensor，但并非全0
   ```

   输出

   ```python
   tensor([[ 0.0000e+00,  1.5846e+29,  0.0000e+00],
           [ 1.5846e+29,  5.6052e-45,  0.0000e+00],
           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
           [ 0.0000e+00,  0.0000e+00,  0.0000e+00],
           [ 0.0000e+00,  1.5846e+29, -2.4336e+02]])
   ```



3. **创建全0的tensor**

   ```python
   x=torch.zeros(5,3)
   ```

   输出

   ```python
   tensor([[0., 0., 0.],
           [0., 0., 0.],
           [0., 0., 0.],
           [0., 0., 0.],
           [0., 0., 0.]])
   ```

   

4. **创建随机tensor**

```python
x=torch.rand(5,3)
```

输出

```python
tensor([[0.4963, 0.7682, 0.0885],
        [0.1320, 0.3074, 0.6341],
        [0.4901, 0.8964, 0.4556],
        [0.6323, 0.3489, 0.4017],
        [0.0223, 0.1689, 0.2939]])
```



5. **创建tensor，指定数据类型**

   ```python
   t=torch.zeros(5,3,dtype=torch.long)
   ```

   输出

   ```python
   tensor([[0, 0, 0],
           [0, 0, 0],
           [0, 0, 0],
           [0, 0, 0],
           [0, 0, 0]])
   ```

   

6. **加法**

   - Approach-1

   ```python
   result=torch.empty(5,3)
   x=torch.rand(5,3)
   y=torch.rand(5,3)
   torch.add(x,y,out=result)#指定输出
   #相当于把x+y的结果直接放到数组result中
   print(result)
   ```

   输出

   ```python
   tensor([[0.9612, 1.1214, 1.2018],
           [0.5273, 1.6704, 1.2042],
           [0.8278, 0.6072, 0.9912],
           [0.7352, 0.9191, 0.5463],
           [0.6223, 1.1334, 1.1030]])
   ```

   - Approach-2（*inplace*操作）

   ```python
   y.add_(x)#注意：PyTorch操作inplace版本都有后缀_, 例如x.copy_(y), x.t_()
   print(y)
   ```

   输出同上

   

7. **改变tensor的形状**

   ```python
   x=torch.rand(3,5)
   
   y=x.view(15)#将x变为1行15列
   z=x.view(5,-1)#将x变为3行5列
   # -1所指的维度可以根据其他维度的值推出来
   print(x.size(),y.size(),z.size())
   
   """"
   注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。
   (顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)
   """"
   ```

   输出

   ```python
   torch.Size([3, 5]) torch.Size([15]) torch.Size([5, 3])
   ```

   

8. **将标量tensor转换为一个python number**

   ```python
   x=torch.rand(1)
   print(x)
   print(x.item())
   ```

   输出

   ```python
   tensor([0.1583])#x,为tensor标量
   0.15825873613357544#x.item(),为一个数字
   ```

   

9. **创建一个数据处于一个range之内的tensor**

   ```python
   x=torch.arange(1,4)#意思就是创建一个tensor，其数据从1增长到3，步长为1（未指定维数的情况下默认为标量）
   print(x)
   ```

   输出

   ```python
   tensor([1, 2, 3])
   ```

   - <u>*Further:*改变维度（使用*view()*）</u>

   ```python
   x=torch.arange(1,4).view(3,1)
   print(x)
   ```

   输出

   ```python
   tensor([[1],
           [2],
           [3]])
   ```

   

10. **广播机制**

    ```python
    x = torch.arange(1, 3).view(1, 2)
    print(x)
    y = torch.arange(1, 4).view(3, 1)
    print(y)
    print(x + y)
    ```

    输出

    ```python
    tensor([[1, 2]])
    tensor([[1],
            [2],
            [3]])
    tensor([[2, 3],
            [3, 4],
            [4, 5]])
    """"
    因为x与y的维度不相等，因此在进行加法运算前，会进行“广播”，实际上就是把x与y各自填充为能够进行合法运算的维度
    x被scale为[[1,2],
            	[1,2],
            	[1,2]]
    y被scale为[[1,1],
            	[2,2],
            	[3,3]]
    #基于各自本身的数据进行维度填充
    """"
    ```

    

11. **打印内存地址**

    ```python
    x = torch.tensor([1, 2])
    y = torch.tensor([3, 4])
    id_before = id(y)
    y = y + x
    
    print(id(y)) 	#140668502790400
    print(id_before)#140668502790336
    """"
    两者内存地址不相等
    新的运算结果需要开辟新的内存空间进行存储
    """"
    ```

    ```python
    x = torch.tensor([1, 2])
    y = torch.tensor([3, 4])
    id_before = id(y)
    y[:] = y + x
    
    print(id(y))	#140624748073088
    print(id_before)#140624748073088
    """"
    两者内存地址相等
    因为索引不需要开辟新的内存空间
    对于上示操作而言，仅仅将新的运算结果存在y的原地址中
    """"
    ```

    注：虽然`view`返回的`Tensor`与源`Tensor`是共享`data`的，但是依然是一个新的`Tensor`（因为`Tensor`除了包含`data`外还有一些其他属性），二者id（内存地址）并不一致。

    

12. **Tensor与Numpy数组的相互转化**

    我们很容易用`numpy()`和`from_numpy()`将`Tensor`和NumPy中的数组相互转换。

    但是需要注意的一点是： **这两个函数所产生的的`Tensor`和NumPy中的数组<u>共享相同的内存</u>（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！**

    1. Tensor转化为Numpy

       **`x.numpy()`**

       ```python
       x=torch.ones(3,3)
       y=x.numpy()
       
       print(f"x={x}\n")
       print(f"y={y}\n")
       #不用import numpy，可直接调用numpy()函数即可
       ```

       输出

       ```python
       x=tensor([[1., 1., 1.],
               [1., 1., 1.],
               [1., 1., 1.]])
       
       y=[[1. 1. 1.]
        [1. 1. 1.]
        [1. 1. 1.]]
       ```

    2. Numpy转化为Tensor

       **`torch.from_numpy(x)`**

       ```python
       import numpy as np
       
       x=np.ones(5)
       y=torch.from_numpy(x)
       
       print(f"x={x},\ny={y}")
       ```

       输出

       ```python
       x=[1. 1. 1. 1. 1.],
       y=tensor([1., 1., 1., 1., 1.], dtype=torch.float64)
       ```

       